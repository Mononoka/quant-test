{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66900114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "Target created: type=price, price_type=mid_price, use_time=False, forward_periods=50, time_window=3.0\n",
      "Target created: type=direction, price_type=mid_price, use_time=False, forward_periods=50, time_window=3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Создание возвратов: 100%|████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 29.65it/s]\n",
      "Создание SMA и EMA: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 16.21it/s]\n",
      "Создание волатильности: 100%|████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 14.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество признаков: 26\n",
      "Инженерия признаков завершена за 0.83 секунд\n",
      "Размеры выборок: train=(37500, 26), val=(12500, 26), test=(7500, 26)\n",
      "Предобработка завершена за 0.16 секунд\n",
      "Проверка распределения признаков...\n",
      "bid_price_0: Train-Val p-value=0.1888, Train-Test p-value=0.3088\n",
      "bid_qty_0: Train-Val p-value=0.6742, Train-Test p-value=0.9385\n",
      "ask_price_0: Train-Val p-value=0.1888, Train-Test p-value=0.2799\n",
      "ask_qty_0: Train-Val p-value=0.4068, Train-Test p-value=0.3954\n",
      "BTC-USD_mid_price: Train-Val p-value=0.1825, Train-Test p-value=0.2893\n",
      "BTC-USD_book_imbalance: Train-Val p-value=0.9211, Train-Test p-value=0.5910\n",
      "BTC-USD_spread: Train-Val p-value=0.9879, Train-Test p-value=0.9799\n",
      "returns_1: Train-Val p-value=0.7923, Train-Test p-value=0.7733\n",
      "returns_5: Train-Val p-value=0.9953, Train-Test p-value=0.9367\n",
      "returns_10: Train-Val p-value=0.9887, Train-Test p-value=0.9780\n",
      "returns_20: Train-Val p-value=0.4032, Train-Test p-value=0.9205\n",
      "sma_5: Train-Val p-value=0.1764, Train-Test p-value=0.2823\n",
      "ema_5: Train-Val p-value=0.1725, Train-Test p-value=0.2823\n",
      "sma_10: Train-Val p-value=0.1764, Train-Test p-value=0.2776\n",
      "ema_10: Train-Val p-value=0.1725, Train-Test p-value=0.2730\n",
      "sma_20: Train-Val p-value=0.1573, Train-Test p-value=0.2446\n",
      "ema_20: Train-Val p-value=0.1591, Train-Test p-value=0.2553\n",
      "volatility_10: Train-Val p-value=0.9845, Train-Test p-value=0.8186\n",
      "volatility_20: Train-Val p-value=0.3645, Train-Test p-value=0.8848\n",
      "imbalance_ma_10: Train-Val p-value=0.7762, Train-Test p-value=0.0507\n",
      "imbalance_lag_1: Train-Val p-value=0.8348, Train-Test p-value=0.3503\n",
      "relative_spread: Train-Val p-value=0.6872, Train-Test p-value=0.8715\n",
      "trade_flow_10: Train-Val p-value=0.7762, Train-Test p-value=0.0507\n",
      "total_volume_5: Train-Val p-value=0.5076, Train-Test p-value=0.4692\n",
      "rsi_14: Train-Val p-value=0.9702, Train-Test p-value=0.9834\n",
      "macd: Train-Val p-value=0.4596, Train-Test p-value=0.7219\n",
      "Обучение регрессии...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6386\n",
      "[LightGBM] [Info] Number of data points in the train set: 37500, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 1.180827\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Регрессия завершена за 7.61 секунд\n",
      "Обучение классификации...\n",
      "[LightGBM] [Info] Number of positive: 21195, number of negative: 21195\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6627\n",
      "[LightGBM] [Info] Number of data points in the train set: 42390, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Классификация завершена за 27.19 секунд\n",
      "\n",
      "Результаты регрессии:\n",
      "rmse_train: 0.000303\n",
      "mae_train: 0.000221\n",
      "rmse_val: 0.000316\n",
      "mae_val: 0.000238\n",
      "rmse_test: 0.000314\n",
      "mae_test: 0.000236\n",
      "\n",
      "Результаты классификации (LGBM):\n",
      "accuracy_train: 0.660640\n",
      "roc_auc_train: 0.734391\n",
      "accuracy_val: 0.535120\n",
      "roc_auc_val: 0.496171\n",
      "accuracy_test: 0.529733\n",
      "precision_test: 0.445299\n",
      "recall_test: 0.225314\n",
      "f1_test: 0.299225\n",
      "roc_auc_test: 0.506682\n",
      "\n",
      "Результаты классификации (XGB):\n",
      "accuracy_train: 0.434987\n",
      "roc_auc_train: 0.562577\n",
      "accuracy_val: 0.430080\n",
      "roc_auc_val: 0.494052\n",
      "accuracy_test: 0.445600\n",
      "precision_test: 0.445600\n",
      "recall_test: 1.000000\n",
      "f1_test: 0.616491\n",
      "roc_auc_test: 0.502314\n",
      "\n",
      "Результаты классификации (ENSEMBLE):\n",
      "accuracy_train: 0.601520\n",
      "roc_auc_train: 0.727675\n",
      "accuracy_val: 0.468560\n",
      "roc_auc_val: 0.495885\n",
      "accuracy_test: 0.483067\n",
      "precision_test: 0.451776\n",
      "recall_test: 0.749850\n",
      "f1_test: 0.563843\n",
      "roc_auc_test: 0.506010\n",
      "\n",
      "Пайплайн завершен за 38.70 секунд\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import ks_2samp\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import os\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "warnings.filterwarnings('ignore')\n",
    "joblib.parallel_backend('threading')\n",
    "\n",
    "def create_target(\n",
    "    df: pl.DataFrame,\n",
    "    instrument_id: str,\n",
    "    forward_periods: int = 50,\n",
    "    time_window: float = 3.0,\n",
    "    use_time: bool = False,\n",
    "    target_type: str = 'price',\n",
    "    price_type: str = 'mid_price'\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Создает целевую переменную для регрессии  и классификации .\n",
    "    \"\"\"\n",
    "    timestamp_col = 'exchange_time'\n",
    "    price_col = f'{instrument_id}_{price_type}'\n",
    "    \n",
    "    result_df = df.clone()\n",
    "    \n",
    "    if use_time:\n",
    "        result_df = result_df.with_columns([\n",
    "            (pl.col(timestamp_col) / 1e9).alias('timestamp_seconds')\n",
    "        ])\n",
    "        future_prices = []\n",
    "        print(\"Создание целевой переменной с учетом времени...\")\n",
    "        for row in tqdm(result_df.iter_rows(named=True), total=result_df.height, desc=\"Обработка строк\"):\n",
    "            current_time = row['timestamp_seconds']\n",
    "            target_time = current_time + time_window\n",
    "            future_rows = result_df.filter(pl.col('timestamp_seconds') >= target_time)\n",
    "            future_price = future_rows[0, price_col] if future_rows.height > 0 else row[price_col]\n",
    "            future_prices.append(future_price)\n",
    "        result_df = result_df.with_columns([\n",
    "            pl.Series(future_prices).alias('future_price')\n",
    "        ])\n",
    "    else:\n",
    "        result_df = result_df.with_columns([\n",
    "            pl.col(price_col).shift(-forward_periods).alias('future_price')\n",
    "        ])\n",
    "    \n",
    "    if target_type == 'price':\n",
    "        result_df = result_df.with_columns([\n",
    "            pl.col('future_price').fill_null(pl.col(price_col).mean())\n",
    "            .replace([float('inf'), float('-inf')], pl.col(price_col).mean())\n",
    "            .alias('future_price')\n",
    "        ])\n",
    "    elif target_type == 'returns':\n",
    "        result_df = result_df.with_columns([\n",
    "            ((pl.col('future_price') - pl.col(price_col)) / (pl.col(price_col) + 1e-6))\n",
    "            .fill_null(0.0).replace([float('inf'), float('-inf')], 0.0)\n",
    "            .alias('future_returns')\n",
    "        ])\n",
    "    elif target_type == 'direction':\n",
    "        result_df = result_df.with_columns([\n",
    "            (pl.col('future_price') > pl.col(price_col)).cast(pl.Int8).alias('future_direction')\n",
    "        ])\n",
    "    \n",
    "    result_df = result_df.drop_nulls(subset=['future_price'])\n",
    "    \n",
    "    # Визуализация распределения цп\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if target_type == 'price':\n",
    "        sns.histplot(result_df['future_price'].to_numpy(), bins=100)\n",
    "        plt.title('Распределение future_price')\n",
    "        plt.savefig('plots/future_price_distribution.png')\n",
    "    elif target_type == 'returns':\n",
    "        sns.histplot(result_df['future_returns'].to_numpy(), bins=100)\n",
    "        plt.title('Распределение future_returns')\n",
    "        plt.savefig('plots/future_returns_distribution.png')\n",
    "    elif target_type == 'direction':\n",
    "        sns.countplot(x=result_df['future_direction'].to_numpy())\n",
    "        plt.title('Распределение future_direction')\n",
    "        plt.savefig('plots/future_direction_distribution.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Target created: type={target_type}, price_type={price_type}, \"\n",
    "          f\"use_time={use_time}, forward_periods={forward_periods}, time_window={time_window}\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def engineer_features(df: pl.DataFrame, instrument_id: str) -> Tuple[pl.DataFrame, List[str]]:\n",
    "    \"\"\"\n",
    "    Признаки из рыночных данных.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    mid_col = f'{instrument_id}_mid_price'\n",
    "    imbalance_col = f'{instrument_id}_book_imbalance'\n",
    "    spread_col = f'{instrument_id}_spread'\n",
    "    bid_vol_col = 'bid_qty_0'\n",
    "    ask_vol_col = 'ask_qty_0'\n",
    "    \n",
    "    result_df = df.clone()\n",
    "    \n",
    "    \n",
    "    required_cols = ['bid_price_0', 'ask_price_0', bid_vol_col, ask_vol_col]\n",
    "    missing_cols = [col for col in required_cols if col not in result_df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing columns in DataFrame: {missing_cols}\")\n",
    "    \n",
    "    # Базовые признаки\n",
    "    result_df = result_df.with_columns([\n",
    "        ((pl.col('bid_price_0') + pl.col('ask_price_0')) / 2).alias(mid_col),\n",
    "        ((pl.col(bid_vol_col) - pl.col(ask_vol_col)) / (pl.col(bid_vol_col) + pl.col(ask_vol_col) + 1e-6)).alias(imbalance_col),\n",
    "        (pl.col('ask_price_0') - pl.col('bid_price_0')).alias(spread_col)\n",
    "    ]).with_columns([\n",
    "        pl.col(mid_col).fill_null(pl.col(mid_col).mean()).replace([float('inf'), float('-inf')], pl.col(mid_col).mean()),\n",
    "        pl.col(imbalance_col).fill_null(0.0).replace([float('inf'), float('-inf')], 0.0),\n",
    "        pl.col(spread_col).fill_null(pl.col(spread_col).mean()).replace([float('inf'), float('-inf')], pl.col(spread_col).mean())\n",
    "    ])\n",
    "    \n",
    "    # Возвраты\n",
    "    for window in tqdm([1, 5, 10, 20], desc=\"Создание возвратов\"):\n",
    "        result_df = result_df.with_columns([\n",
    "            ((pl.col(mid_col) / pl.col(mid_col).shift(window) - 1))\n",
    "            .fill_null(0.0).replace([float('inf'), float('-inf')], 0.0)\n",
    "            .alias(f'returns_{window}')\n",
    "        ])\n",
    "    \n",
    "    # SMA и EMA\n",
    "    for window in tqdm([5, 10, 20], desc=\"Создание SMA и EMA\"):\n",
    "        result_df = result_df.with_columns([\n",
    "            pl.col(mid_col).rolling_mean(window).fill_null(pl.col(mid_col).mean())\n",
    "            .replace([float('inf'), float('-inf')], pl.col(mid_col).mean())\n",
    "            .alias(f'sma_{window}'),\n",
    "            pl.col(mid_col).ewm_mean(span=window).fill_null(pl.col(mid_col).mean())\n",
    "            .replace([float('inf'), float('-inf')], pl.col(mid_col).mean())\n",
    "            .alias(f'ema_{window}')\n",
    "        ])\n",
    "    \n",
    "    # Волатильность\n",
    "    for window in tqdm([10, 20], desc=\"Создание волатильности\"):\n",
    "        result_df = result_df.with_columns([\n",
    "            pl.col('returns_1').rolling_std(window).fill_null(0.0)\n",
    "            .replace([float('inf'), float('-inf')], 0.0)\n",
    "            .alias(f'volatility_{window}')\n",
    "        ])\n",
    "    \n",
    "    # Дисбаланс и спред\n",
    "    result_df = result_df.with_columns([\n",
    "        pl.col(imbalance_col).rolling_mean(10).fill_null(0.0).replace([float('inf'), float('-inf')], 0.0).alias('imbalance_ma_10'),\n",
    "        pl.col(imbalance_col).shift(1).fill_null(0.0).replace([float('inf'), float('-inf')], 0.0).alias('imbalance_lag_1'),\n",
    "        (pl.col(spread_col) / (pl.col(mid_col) + 1e-6)).fill_null(0.0).replace([float('inf'), float('-inf')], 0.0).alias('relative_spread')\n",
    "    ])\n",
    "    \n",
    "    # Объемы\n",
    "    result_df = result_df.with_columns([\n",
    "        ((pl.col(bid_vol_col) - pl.col(ask_vol_col)) / (pl.col(bid_vol_col) + pl.col(ask_vol_col) + 1e-6))\n",
    "        .rolling_mean(10).fill_null(0.0).replace([float('inf'), float('-inf')], 0.0)\n",
    "        .alias('trade_flow_10'),\n",
    "        (pl.col(bid_vol_col) + pl.col(ask_vol_col)).rolling_sum(5).fill_null(0.0)\n",
    "        .replace([float('inf'), float('-inf')], 0.0)\n",
    "        .alias('total_volume_5')\n",
    "    ])\n",
    "    \n",
    "    # RSI\n",
    "    def calculate_rsi(prices: pl.Series, period: int = 14) -> pl.Series:\n",
    "        delta = prices.diff()\n",
    "        gain = delta.clip(lower_bound=0)\n",
    "        loss = (-delta).clip(lower_bound=0)\n",
    "        avg_gain = gain.rolling_mean(period)\n",
    "        avg_loss = loss.rolling_mean(period)\n",
    "        rs = avg_gain / (avg_loss + 1e-6)\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        return rsi.fill_null(50.0).replace([float('inf'), float('-inf')], 50.0)\n",
    "    \n",
    "    result_df = result_df.with_columns([\n",
    "        calculate_rsi(pl.col(mid_col), period=14).alias('rsi_14')\n",
    "    ])\n",
    "    \n",
    "    # MACD\n",
    "    result_df = result_df.with_columns([\n",
    "        (pl.col(mid_col).ewm_mean(span=12) - pl.col(mid_col).ewm_mean(span=26))\n",
    "        .fill_null(0.0).replace([float('inf'), float('-inf')], 0.0)\n",
    "        .alias('macd')\n",
    "    ])\n",
    "    \n",
    "    # Формирование списка признаков\n",
    "    exclude_patterns = ['future_', 'exchange_time', 'adapter_time', 'instrument_id']\n",
    "    feature_cols = [col for col in result_df.columns if not any(pattern in col for pattern in exclude_patterns)]\n",
    "    feature_cols = [col for col in feature_cols if col != instrument_id]\n",
    "    \n",
    "    print(f\"Количество признаков: {len(feature_cols)}\")\n",
    "    print(f\"Инженерия признаков завершена за {time.time() - start_time:.2f} секунд\")\n",
    "    return result_df, feature_cols\n",
    "\n",
    "def preprocess_data(\n",
    "    df: pl.DataFrame,\n",
    "    feature_cols: List[str],\n",
    "    target_col: str,\n",
    "    n_splits: int = 3,\n",
    "    outlier_threshold: float = 3.0,\n",
    "    sample_size: int = 50000\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, RobustScaler, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Предобработка данных: масштабирование, удаление выбросов, разделение на выборки.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if sample_size:\n",
    "        df = df.sample(n=sample_size, shuffle=False)\n",
    "    \n",
    "    X = df.select(feature_cols).to_numpy()\n",
    "    y = df[target_col].to_numpy()\n",
    "    \n",
    "  \n",
    "    X = np.nan_to_num(X, nan=np.nanmean(X, axis=0), posinf=np.nanmean(X, axis=0), neginf=np.nanmean(X, axis=0))\n",
    "    y = np.nan_to_num(y, nan=np.nanmean(y), posinf=np.nanmean(y), neginf=np.nanmean(y))\n",
    "    \n",
    "    # Удаление выбросов\n",
    "    z_scores = np.abs((y - np.mean(y)) / np.std(y))\n",
    "    mask = z_scores < outlier_threshold\n",
    "    X, y = X[mask], y[mask]\n",
    "    indices = np.arange(len(mask))[mask]\n",
    "    \n",
    "   \n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    train_idx, val_idx = list(tscv.split(X))[-1]\n",
    "    test_size = 0.15\n",
    "    split_idx = int(len(X) * (1 - test_size))\n",
    "    \n",
    "    X_train, X_val, X_test = X[train_idx], X[val_idx], X[split_idx:]\n",
    "    y_train, y_val, y_test = y[train_idx], y[val_idx], y[split_idx:]\n",
    "    train_indices, val_indices, test_indices = indices[train_idx], indices[val_idx], indices[split_idx:]\n",
    "    \n",
    "   \n",
    "    scaler = RobustScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    print(f\"Размеры выборок: train={X_train.shape}, val={X_val.shape}, test={X_test.shape}\")\n",
    "    print(f\"Предобработка завершена за {time.time() - start_time:.2f} секунд\")\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, scaler, train_indices, val_indices, test_indices\n",
    "\n",
    "def check_data_distribution(\n",
    "    X_train: np.ndarray,\n",
    "    X_val: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    "    feature_cols: List[str],\n",
    "    y_train: np.ndarray,\n",
    "    y_val: np.ndarray,\n",
    "    y_test: np.ndarray\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Проверка распределения признаков и целевой переменной.\n",
    "    \"\"\"\n",
    "    print(\"Проверка распределения признаков...\")\n",
    "    for i, col in enumerate(feature_cols):\n",
    "        train_val_p = ks_2samp(X_train[:, i], X_val[:, i]).pvalue\n",
    "        train_test_p = ks_2samp(X_train[:, i], X_test[:, i]).pvalue\n",
    "        print(f\"{col}: Train-Val p-value={train_val_p:.4f}, Train-Test p-value={train_test_p:.4f}\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.kdeplot(y_train, label='Train', color='blue')\n",
    "    sns.kdeplot(y_val, label='Validation', color='orange')\n",
    "    sns.kdeplot(y_test, label='Test', color='green')\n",
    "    plt.title('Распределение целевой переменной')\n",
    "    plt.legend()\n",
    "    plt.savefig('plots/target_split_distribution.png')\n",
    "    plt.close()\n",
    "\n",
    "def train_and_evaluate(\n",
    "    X_train: np.ndarray,\n",
    "    X_val: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    y_val: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    feature_cols: List[str],\n",
    "    df: pl.DataFrame,\n",
    "    train_indices: np.ndarray,\n",
    "    val_indices: np.ndarray,\n",
    "    test_indices: np.ndarray,\n",
    "    regression_params: dict,\n",
    "    classification_params: dict\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Обучение и оценка моделей.\n",
    "    \"\"\"\n",
    "    results = {'regression': {}, 'classification_lgbm': {}, 'classification_xgb': {}, 'classification_ensemble': {}}\n",
    "    \n",
    "    # Регрессия\n",
    "    start_time = time.time()\n",
    "    print(\"Обучение регрессии...\")\n",
    "    reg_model = LGBMRegressor(random_state=42)\n",
    "    reg_grid = RandomizedSearchCV(\n",
    "        reg_model, regression_params, n_iter=10, cv=3, scoring='neg_mean_squared_error', n_jobs=2, random_state=42\n",
    "    )\n",
    "    reg_grid.fit(X_train, y_train)\n",
    "    reg_best = reg_grid.best_estimator_\n",
    "    \n",
    "    for split, X, y in [('train', X_train, y_train), ('val', X_val, y_val), ('test', X_test, y_test)]:\n",
    "        y_pred = reg_best.predict(X)\n",
    "        results['regression'][f'rmse_{split}'] = mean_squared_error(y, y_pred, squared=False)\n",
    "        results['regression'][f'mae_{split}'] = mean_absolute_error(y, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    y_pred_test = reg_best.predict(X_test)\n",
    "    plt.scatter(y_test, y_pred_test, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    plt.xlabel('Фактические значения')\n",
    "    plt.ylabel('Предсказанные значения')\n",
    "    plt.title('Фактические vs Предсказанные (Регрессия)')\n",
    "    plt.savefig('plots/predictions_scatter.png')\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=reg_best.feature_importances_, y=feature_cols)\n",
    "    plt.title('Важность признаков (Регрессия)')\n",
    "    plt.savefig('plots/feature_importance_regression.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Регрессия завершена за {time.time() - start_time:.2f} секунд\")\n",
    "    \n",
    "    # Классификация\n",
    "    start_time = time.time()\n",
    "    print(\"Обучение классификации...\")\n",
    "    y_train_class = df['future_direction'][train_indices].to_numpy()\n",
    "    y_val_class = df['future_direction'][val_indices].to_numpy()\n",
    "    y_test_class = df['future_direction'][test_indices].to_numpy()\n",
    "    \n",
    "    y_train_class = np.nan_to_num(y_train_class, nan=0)\n",
    "    smote = SMOTE(random_state=42, sampling_strategy='auto')\n",
    "    X_train_resampled, y_train_class_resampled = smote.fit_resample(X_train, y_train_class)\n",
    "    \n",
    "    # LightGBM\n",
    "    lgbm_model = LGBMClassifier(random_state=42, class_weight='balanced')\n",
    "    lgbm_grid = RandomizedSearchCV(\n",
    "        lgbm_model, classification_params, n_iter=10, cv=3, scoring='f1', n_jobs=2, random_state=42\n",
    "    )\n",
    "    lgbm_grid.fit(X_train_resampled, y_train_class_resampled)\n",
    "    lgbm_best = lgbm_grid.best_estimator_\n",
    "    \n",
    "    # XGBoost\n",
    "    xgb_model = XGBClassifier(\n",
    "        random_state=42, \n",
    "        scale_pos_weight=len(y_train_class[y_train_class == 0]) / len(y_train_class[y_train_class == 1])\n",
    "    )\n",
    "    xgb_grid = RandomizedSearchCV(\n",
    "        xgb_model, classification_params, n_iter=10, cv=3, scoring='f1', n_jobs=2, random_state=42\n",
    "    )\n",
    "    xgb_grid.fit(X_train_resampled, y_train_class_resampled)\n",
    "    xgb_best = xgb_grid.best_estimator_\n",
    "    \n",
    "    # Ансамбль\n",
    "    ensemble_model = VotingClassifier(\n",
    "        estimators=[('lgbm', lgbm_best), ('xgb', xgb_best)],\n",
    "        voting='soft'\n",
    "    )\n",
    "    ensemble_model.fit(X_train_resampled, y_train_class_resampled)\n",
    "    \n",
    "    # Оценка моделей\n",
    "    for model_name, model in [('lgbm', lgbm_best), ('xgb', xgb_best), ('ensemble', ensemble_model)]:\n",
    "        for split, X, y in [('train', X_train, y_train_class), ('val', X_val, y_val_class), ('test', X_test, y_test_class)]:\n",
    "            y_pred = model.predict(X)\n",
    "            y_proba = model.predict_proba(X)[:, 1]\n",
    "            results[f'classification_{model_name}'][f'accuracy_{split}'] = accuracy_score(y, y_pred)\n",
    "            if split == 'test':\n",
    "                results[f'classification_{model_name}']['precision_test'] = precision_score(y, y_pred)\n",
    "                results[f'classification_{model_name}']['recall_test'] = recall_score(y, y_pred)\n",
    "                results[f'classification_{model_name}']['f1_test'] = f1_score(y, y_pred)\n",
    "            results[f'classification_{model_name}'][f'roc_auc_{split}'] = roc_auc_score(y, y_proba)\n",
    "        \n",
    "        if model_name != 'ensemble':\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.barplot(x=model.feature_importances_, y=feature_cols)\n",
    "            plt.title(f'Важность признаков ({model_name.upper()} Классификация)')\n",
    "            plt.savefig(f'plots/feature_importance_classification_{model_name}.png')\n",
    "            plt.close()\n",
    "        \n",
    "        cm = confusion_matrix(y_test_class, model.predict(X_test))\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Матрица ошибок ({model_name.upper()} Классификация)')\n",
    "        plt.xlabel('Предсказанный класс')\n",
    "        plt.ylabel('Фактический класс')\n",
    "        plt.savefig(f'plots/confusion_matrix_{model_name}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    print(f\"Классификация завершена за {time.time() - start_time:.2f} секунд\")\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Параметры для моделей\n",
    "    instrument_id = 'BTC-USD'\n",
    "    regression_params = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [5, 7, 8],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "    classification_params = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [5, 7, 8],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "    \n",
    "    \n",
    "    print(\"Загрузка данных...\")\n",
    "    df = pl.read_parquet(\"C:/Users/wertu/quant_assignment/data/parsed_ondo/2820_2025-02-18_bybit_book_1_fc.parquet\")\n",
    "    \n",
    "    # Проверка столбцов\n",
    "    required_cols = ['bid_price_0', 'ask_price_0', 'bid_qty_0', 'ask_qty_0', 'exchange_time']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing columns: {missing_cols}\")\n",
    "    \n",
    "  \n",
    "    df = df.with_columns([\n",
    "        ((pl.col('bid_price_0') + pl.col('ask_price_0')) / 2).alias(f'{instrument_id}_mid_price')\n",
    "        .fill_null(pl.col('bid_price_0').mean())\n",
    "        .replace([float('inf'), float('-inf')], pl.col('bid_price_0').mean())\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    df_regression = create_target(\n",
    "        df=df, instrument_id=instrument_id, forward_periods=50, use_time=False, \n",
    "        target_type='price', price_type='mid_price'\n",
    "    )\n",
    "    df_classification = create_target(\n",
    "        df=df, instrument_id=instrument_id, forward_periods=50, use_time=False, \n",
    "        target_type='direction', price_type='mid_price'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    df_regression, feature_cols = engineer_features(df_regression, instrument_id)\n",
    "    \n",
    "    \n",
    "    X_train, X_val, X_test, y_train, y_val, y_test, scaler, train_indices, val_indices, test_indices = preprocess_data(\n",
    "        df=df_regression, feature_cols=feature_cols, target_col='future_price', \n",
    "        n_splits=3, outlier_threshold=3.0, sample_size=50000\n",
    "    )\n",
    "    \n",
    "   \n",
    "    check_data_distribution(X_train, X_val, X_test, feature_cols, y_train, y_val, y_test)\n",
    "    \n",
    "    \n",
    "    results = train_and_evaluate(\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test, feature_cols, df_classification,\n",
    "        train_indices, val_indices, test_indices, regression_params, classification_params\n",
    "    )\n",
    "    \n",
    "    \n",
    "    print(\"\\nРезультаты регрессии:\")\n",
    "    for metric, value in results['regression'].items():\n",
    "        print(f\"{metric}: {value:.6f}\")\n",
    "    \n",
    "    for model in ['lgbm', 'xgb', 'ensemble']:\n",
    "        print(f\"\\nРезультаты классификации ({model.upper()}):\")\n",
    "        for metric, value in results[f'classification_{model}'].items():\n",
    "            print(f\"{metric}: {value:.6f}\")\n",
    "    \n",
    "    print(f\"\\nПайплайн завершен за {time.time() - start_time:.2f} секунд\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91357d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
